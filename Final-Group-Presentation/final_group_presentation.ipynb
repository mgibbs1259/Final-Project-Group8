{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><strong><center>FocusedFashion</center><strong></h1>\n",
    "<h3><center>Mary Gibbs and Jessica Fogerty</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Introduction</center></h1>\n",
    "<h2><center>Problem</center></h2>\n",
    "<center>We all have our favorite pieces of clothing that we consistently wear. Over time, these clothing items may not fit anymore or degrade in quality. Subsequently, it may be difficult to find the same clothing item or time-intensive to find similar clothing items due to the vast amount of clothing websites and clothing retail stores. This is a common issue for both of us, and it is something we would like to streamline!</center>\n",
    "<h2><center>Solution</center></h2>\n",
    "<center>Our solution involves a two-step approach. First, we train a convolutional neural network on fashion images in order to extract the feature maps associated with different clothing items. Second, we use the feature maps as input to a KNN model that will find the five closest neighbors to a given query image that will serve as recommendations.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Overview</center></h1>\n",
    "<ul>\n",
    "<li>Related Work</li>\n",
    "<li>Dataset</li>\n",
    "<li>Models</li>\n",
    "<li>Recommendation</li>\n",
    "<li>Conclusion</li>\n",
    "<li>Limitations & Future Work</li>\n",
    "<li>References</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> <center>Related Work</center></h1>\n",
    "\n",
    "- <font size=\"5\"> <b> Recommending Similar Fashion Images with Deep Learning (Le, 2019) </b>\n",
    " \n",
    "    - Used the DeepFashion dataset and focused on tops  \n",
    "    - Used ResNet to classify the clothing into 6 classes and obtain feature maps\n",
    "    - Implemented a nearest neightbors-based search on feature maps\n",
    "    \n",
    "- <b>Image Based Fashion Product Recommendation with Deep Learning (Tuinhof, Pirker, & Haltmeier, 2018) </b>\n",
    "    \n",
    "   - Used the ImageLab Garment Selection and Color Classification dataset\n",
    "   - Used AlexNet and BN-inception to extract feature maps\n",
    "   - Implemented a KNN with Euclidean distance to return ranked recommendations\n",
    "- <b>FashionNet: Personalized Outfit Recommendation with Deep Neural Network (He & Hu, 2018)</b>\n",
    "    - Used a personalized, user-based scoring approach based on fashion images that constitute an outfit\n",
    "    - Concatenated all images in an outfit and used CNN models, specifically VGGNet, to obtain a probability that the user likes or dislikes the outfit </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Dataset</center></h1>\n",
    "<ul>\n",
    "<h3><center>Dataset comes from the Kaggle competition: iMaterialist Challenge (Fashion) at FGVC5</center></h3>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"kaggle_fashion_dataset.png\" alt=\"centered image\" />\n",
    "</center>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center>Dataset Preprocessing</center></h1>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"dataset_summary.png\" alt=\"centered image\" />\n",
    "</center>\n",
    "<center>\n",
    "    <img src=\"labels_summary.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center>Label Distribution</center></h1>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"labels_histogram.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Label Distribution\n",
    "- Minimum number of labels for an image: 6 </li>\n",
    "- Maximum number of labels for an image: 142 </li>\n",
    "- Average number of labels for an image: 36 </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center>Label Frequency</center></h1>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"labels_word_cloud.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Models</center></h1>\n",
    "\n",
    "- <h5>Simple CNNs</h5>\n",
    "\n",
    "    - Our own architecture\n",
    "<br>\n",
    "\n",
    "- <h5>Pretrained CNN</h5>\n",
    "    \n",
    "    - MobileNetV2\n",
    "<br>\n",
    "\n",
    "- <h5>Performance metrics</h5>\n",
    "    \n",
    "    - Binary cross-entropy loss with logits \n",
    "    - Micro-averaged F1\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Simple CNN </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center> Architecture </center></h1>\n",
    "<center>\n",
    "    <img src=\"simple_cnn_architecture.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center>Model Summary</center></h1>\n",
    "<h4><center>Input Size: (3,50,50)</center></h4>\n",
    "<center>\n",
    "    <img src=\"jessica_model_5_summary.png\" alt=\"centered image\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"convolution_calculations.png\" alt=\"centered image\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center>Training Loss</center></h1>\n",
    "<center>\n",
    "    <img src=\"jessica_model_5_loss_plot.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center>Test Performance</center></h1>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"jessica_model_5_f1_plot.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center>MobileNetV2</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center>Convolutions</center></h1>\n",
    "<h3><center>Makes use of depthwise convolutions followed by pointwise convolutions</center></h3>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"mobilenet_diagram_1.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center>Architecture</center></h1>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"mobilenet_diagram_2.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "MobileNetV2\n",
    "- Expansion layer - input low dimension, increase dimensions\n",
    "- Depthwise layer - filter on high dimensions\n",
    "- Projection layer - decrease dimensions, output low dimension\n",
    "- Residual connection - gradient flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center>Training Loss</center></h1>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"mobilenet_loss_plot.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1><center>Test Performance</center></h1>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"mobilenet_f1_plot.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Recommendation System</center></h1>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"recommendation_diagram.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Recommendations</center></h1>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"jeans_recommendations.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Recommendations</center></h1>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"skirt_recommendations.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Recommendations</center></h1>\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"jessica_recommendations.png\" alt=\"centered image\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Conclusion</center></h1>\n",
    "<ul>\n",
    "<li>Built a deep learning-based fashion recommendation system</li>\n",
    "<li>MobileNetV2 feature extraction w/ KNN ranking > Simple CNN feature extraction w/ KNN ranking > Baseline KNN ranking</li>\n",
    "<li>Euclidean distance</li>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Limitations</center></h1>\n",
    "<ul>\n",
    "<li>Due to memory constraints, we could only use a small image/batch size</li>\n",
    "<li>With 300,000 images, training models is a time intensive process</li>\n",
    "<li>Fashion dataset contained a class imbalance and did not contain bounding boxes or pose estimation</li>\n",
    "</ul>\n",
    "<h1><center>Future Work</center></h1>\n",
    "<ul>\n",
    "<li>Deal with class imbalance in the fashion dataset</li>\n",
    "<li>Work with the DeepFashion and DeepFashion2 datasets, which include bounding boxes and pose estimation that we can use to extract feature maps for individual clothing items</li>\n",
    "<li>Try assessing model performance based on Top-k accuracy since we are only interested in the first k items being correct/relevant </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>References</center></h1>\n",
    "<font size=\"4.5\">- He, T., & Hu, Y. (2018). FashionNet: Personalized Outfit Recommendation with Deep Neural Network, 1–8.<br>\n",
    "- Hollemans, M. (n.d.). Retrieved from https://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/.<br>\n",
    "- Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., … Adam, H. (2017). MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications.<br>\n",
    "- Huang, G., Liu, Z., & van der Maaten, L. (2018). Densely Connected Convolutional Networks. Densely Connected Convolutional Networks, 1–8. Retrieved from https://arxiv.org/pdf/1608.06993.pdf <br>\n",
    "- Le, J. (2019, August 16). Recommending Similar Fashion Images with Deep Learning. Retrieved from https://blog.floydhub.com/similar-fashion-images/. <br>\n",
    "- Nazi, Z. A., & Abir, T. A. (2018). Automatic Skin Lesion Segmentation and Melanoma Detection: Transfer Learning approach with U-Net and DCNN-SVM. International Joint Conference on Computational Intelligence. Retrieved from https://www.researchgate.net/publication/330564744_Automatic_Skin_Lesion_Segmentation_and_Melanoma_Detection_Transfer_Learning_approach_with_U-Net_and_DCNN-SVM <br>\n",
    "- Tsang, S.-H. (2019, March 20). Review: DenseNet - Dense Convolutional Network (Image Classification). Retrieved from https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803.<br>\n",
    "- Tuinhof, H., Pirker, C., & Haltmeier, M. (2018). Image Based Fashion Product Recommendation with Deep Learning, 1–10.</font>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
